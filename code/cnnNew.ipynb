{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dl1/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9320283792285231798\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10654105600\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 13703534341667828033\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10965090304\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 7615065375862468699\n",
      "physical_device_desc: \"device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:b3:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\"\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "\n",
    "import gzip\n",
    "import sys\n",
    "if (sys.version_info > (3, 0)):\n",
    "    import pickle as pkl\n",
    "else: #Python 2.7 imports\n",
    "    import cPickle as pkl\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten, concatenate\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.regularizers import Regularizer\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordIdxLookup(word, word_idx_map):\n",
    "    if word in word_idx_map:\n",
    "        return word_idx_map[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!\n"
     ]
    }
   ],
   "source": [
    "data = pkl.load(gzip.open(\"/home/dl1/Arav/Neuralnets/Session 2 - Sentence CNN/code/pkl/data.pkl.gz\",\"rb\"))\n",
    "print(\"data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = data['train']['labels']\n",
    "train_sentences = data['train']['sentences']\n",
    "\n",
    "dev_labels = data['dev']['labels']\n",
    "dev_sentences = data['dev']['sentences']\n",
    "\n",
    "test_labels = data['test']['labels']\n",
    "test_sentences = data['test']['sentences']\n",
    "\n",
    "word_embeddings = data['wordEmbeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sentence: 59\n"
     ]
    }
   ],
   "source": [
    "# :: Find the longest sentence in our dataset ::\n",
    "max_sentence_len = 0\n",
    "for sentence in train_sentences + dev_sentences + test_sentences:\n",
    "    max_sentence_len = max(len(sentence), max_sentence_len)\n",
    "\n",
    "print(\"Longest sentence: %d\" % max_sentence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5330, 59)\n",
      "X_dev shape: (2664, 59)\n",
      "X_test shape: (2668, 59)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_dev = np.array(dev_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "X_train = sequence.pad_sequences(train_sentences, maxlen=max_sentence_len)\n",
    "X_dev = sequence.pad_sequences(dev_sentences, maxlen=max_sentence_len)\n",
    "X_test = sequence.pad_sequences(test_sentences, maxlen=max_sentence_len)\n",
    "\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_dev shape:', X_dev.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "#  :: Create the network :: \n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "# set parameters:\n",
    "batch_size = 50\n",
    "\n",
    "nb_filter = 50\n",
    "filter_lengths = [1,2,3]\n",
    "hidden_dims = 100\n",
    "nb_epoch = 10\n",
    "\n",
    "\n",
    "\n",
    "words_input = Input(shape=(max_sentence_len,), dtype='int32', name='words_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(59)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Our word embedding layer\n",
    "wordsEmbeddingLayer = Embedding(word_embeddings.shape[0],\n",
    "                    word_embeddings.shape[1],                                     \n",
    "                    weights=[word_embeddings],\n",
    "                    trainable=False)\n",
    "\n",
    "words = wordsEmbeddingLayer(words_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words_input (InputLayer)        (None, 59)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 59, 300)      4966200     words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 59, 50)       15050       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 59, 50)       30050       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 59, 50)       45050       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 50)           0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 50)           0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 50)           0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 150)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 150)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          15100       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            101         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 5,071,551\n",
      "Trainable params: 105,351\n",
      "Non-trainable params: 4,966,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Now we add a variable number of convolutions\n",
    "words_convolutions = []\n",
    "for filter_length in filter_lengths:\n",
    "    words_conv = Convolution1D(filters=nb_filter,\n",
    "                            kernel_size=filter_length,\n",
    "                            padding='same',\n",
    "                            activation='relu',\n",
    "                            strides=1)(words)\n",
    "                            \n",
    "    words_conv = GlobalMaxPooling1D()(words_conv)      \n",
    "    \n",
    "    words_convolutions.append(words_conv)  \n",
    "\n",
    "output = concatenate(words_convolutions)\n",
    "\n",
    "\n",
    "\n",
    "# We add a vanilla hidden layer together with dropout layers:\n",
    "output = Dropout(0.5)(output)\n",
    "output = Dense(hidden_dims, activation='tanh', kernel_regularizer=keras.regularizers.l2(0.01))(output)\n",
    "output = Dropout(0.25)(output)\n",
    "\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "output = Dense(1, activation='sigmoid',  kernel_regularizer=keras.regularizers.l2(0.01))(output)\n",
    "\n",
    "model = Model(inputs=[words_input], outputs=[output])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------- Epoch 1 ------------\n",
      "Epoch 1/1\n",
      "5330/5330 [==============================] - 2s 305us/step - loss: 1.5283 - acc: 0.5762\n",
      "Val-Accuracy: 71.51% (loss: 1.1190)\n",
      "Test-Accuracy: 70.50% (loss: 1.1249)\n",
      "\n",
      "------------- Epoch 2 ------------\n",
      "Epoch 1/1\n",
      "5330/5330 [==============================] - 1s 152us/step - loss: 0.9384 - acc: 0.7265\n",
      "Val-Accuracy: 76.80% (loss: 0.7631)\n",
      "Test-Accuracy: 75.19% (loss: 0.7756)\n",
      "\n",
      "------------- Epoch 3 ------------\n",
      "Epoch 1/1\n",
      "5330/5330 [==============================] - 1s 151us/step - loss: 0.6698 - acc: 0.7814\n",
      "Val-Accuracy: 77.03% (loss: 0.6307)\n",
      "Test-Accuracy: 76.01% (loss: 0.6463)\n",
      "\n",
      "------------- Epoch 4 ------------\n",
      "Epoch 1/1\n",
      "5330/5330 [==============================] - 1s 150us/step - loss: 0.5368 - acc: 0.8094\n",
      "Val-Accuracy: 78.64% (loss: 0.5527)\n",
      "Test-Accuracy: 76.80% (loss: 0.5714)\n",
      "\n",
      "------------- Epoch 5 ------------\n",
      "Epoch 1/1\n",
      "5330/5330 [==============================] - 1s 149us/step - loss: 0.4619 - acc: 0.8375\n",
      "Val-Accuracy: 78.23% (loss: 0.5311)\n",
      "Test-Accuracy: 77.02% (loss: 0.5440)\n",
      "\n",
      "------------- Epoch 6 ------------\n",
      "Epoch 1/1\n",
      "5330/5330 [==============================] - 1s 149us/step - loss: 0.4106 - acc: 0.8555\n",
      "Val-Accuracy: 76.80% (loss: 0.5570)\n",
      "Test-Accuracy: 76.01% (loss: 0.5772)\n",
      "\n",
      "------------- Epoch 7 ------------\n",
      "Epoch 1/1\n",
      "5330/5330 [==============================] - 1s 149us/step - loss: 0.3652 - acc: 0.8814\n",
      "Val-Accuracy: 78.30% (loss: 0.5421)\n",
      "Test-Accuracy: 76.99% (loss: 0.5628)\n",
      "\n",
      "------------- Epoch 8 ------------\n",
      "Epoch 1/1\n",
      "5330/5330 [==============================] - 1s 149us/step - loss: 0.3396 - acc: 0.8897\n",
      "Val-Accuracy: 78.64% (loss: 0.5263)\n",
      "Test-Accuracy: 78.30% (loss: 0.5379)\n",
      "\n",
      "------------- Epoch 9 ------------\n",
      "Epoch 1/1\n",
      "5330/5330 [==============================] - 1s 154us/step - loss: 0.3110 - acc: 0.9105\n",
      "Val-Accuracy: 79.09% (loss: 0.5398)\n",
      "Test-Accuracy: 78.00% (loss: 0.5572)\n",
      "\n",
      "------------- Epoch 10 ------------\n",
      "Epoch 1/1\n",
      "5330/5330 [==============================] - 1s 152us/step - loss: 0.2906 - acc: 0.9171\n",
      "Val-Accuracy: 79.20% (loss: 0.5425)\n",
      "Test-Accuracy: 78.15% (loss: 0.5576)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nb_epoch):\n",
    "    print(\"\\n------------- Epoch %d ------------\" % (epoch+1))\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=1)\n",
    "    \n",
    "    #Use Keras to compute the loss and the accuracy\n",
    "    dev_loss, dev_accuracy = model.evaluate(X_dev, y_dev, verbose=False)\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "    \n",
    "  \n",
    "    print(\"Val-Accuracy: %.2f%% (loss: %.4f)\" % (dev_accuracy*100, dev_loss))\n",
    "    print(\"Test-Accuracy: %.2f%% (loss: %.4f)\" % (test_accuracy*100, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04080284], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!\n"
     ]
    }
   ],
   "source": [
    "result_data = pkl.load(gzip.open(\"/home/dl1/Arav/Neuralnets/Session 2 - Sentence CNN/code/pkl/resultdata`.pkl.gz\",\"rb\"))\n",
    "print(\"data loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1694, 4694, 7, 136, 11, 1786, 259, 113, 1508, 308, 1, 1]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_X = sequence.pad_sequences(result_data, maxlen=max_sentence_len)\n",
    "# result_data.extend([0] * (59 - len(result_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    2, 1694, 4694,    7,  136,   11, 1786,  259,  113,\n",
       "        1508,  308,    1,    1]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_y_pred = model.predict(result_X, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9560446]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
